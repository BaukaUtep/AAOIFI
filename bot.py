import os
import time
import requests
import json
import re

from openai import OpenAI
from langdetect import detect
from pinecone import Pinecone       # â† Ğ²Ğ¼ĞµÑÑ‚Ğ¾ pinecone.init()

# â”€â”€â”€ 1. ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TELEGRAM_TOKEN     = os.getenv("TELEGRAM_TOKEN")        # Ğ²Ğ°Ñˆ Telegram token
OPENAI_API_KEY     = os.getenv("OPENAI_API_KEY")        # Ğ²Ğ°Ñˆ OpenAI key
PINECONE_API_KEY   = os.getenv("PINECONE_API_KEY")      # Ğ²Ğ°Ñˆ Pinecone key
PINECONE_ENV       = os.getenv("PINECONE_ENVIRONMENT")  # e.g. "aped-4627-b74a"
PINECONE_INDEX     = "aaofi-standards"

EMBED_MODEL        = "text-embedding-ada-002"
CHAT_MODEL         = "gpt-3.5-turbo"
TOP_K              = 5
TELEGRAM_API       = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}"

# â”€â”€â”€ 2. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai = OpenAI(api_key=OPENAI_API_KEY)

# â† Ğ—Ğ´ĞµÑÑŒ Ğ¼Ñ‹ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ pinecone.init()
pc = Pinecone(
    api_key=PINECONE_API_KEY,
     environment=PINECONE_ENV
)
index = pc.Index(PINECONE_INDEX)

# â”€â”€â”€ 3. Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Telegram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_updates(offset=None, timeout=30):
    r = requests.get(f"{TELEGRAM_API}/getUpdates", params={"offset": offset, "timeout": timeout})
    return r.json().get("result", [])

def send_message(chat_id, text):
    requests.get(
        f"{TELEGRAM_API}/sendMessage",
        params={"chat_id": chat_id, "text": text}
    )

# â”€â”€â”€ 4. Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def answer_question(question: str) -> str:
    # â”€â”€ 0) ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ² Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞµ ĞºĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ†Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    is_cyrillic = bool(re.search(r"[\u0400-\u04FF]", question))

    # â”€â”€ 1) Ğ•ÑĞ»Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° ĞºĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ†Ğµ, Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ ĞµĞ³Ğ¾ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¸Ğ¹ â”€â”€â”€â”€â”€â”€â”€
    if is_cyrillic:
        tran = openai.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role":"system", "content":"Translate the following into English, preserving meaning and style:"},
                {"role":"user",   "content": question}
            ]
        )
        eng_question = tran.choices[0].message.content.strip()
    else:
        eng_question = question

    # â”€â”€ 2) Embedding + Ğ¿Ğ¾Ğ¸ÑĞº Ğ² Pinecone â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    resp = openai.embeddings.create(model=EMBED_MODEL, input=eng_question)
    q_emb = resp.data[0].embedding

    qr = index.query(vector=q_emb, top_k=TOP_K, include_metadata=True)
    contexts = []
    for match in qr.matches:
        md    = match.metadata
        txt   = md.get("chunk_text","")
        title = md.get("section_title","")
        num   = md.get("standard_number","")
        contexts.append(f"{title} (Std {num}):\n{txt}")

    # â”€â”€ 3) Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    system = {
        "role":"system",
        "content":(
            "You are a knowledgeable AAOIFI standards expert. "
            "Using only the provided excerpts, compose a coherent and detailed answer "
            "that explains and synthesizes the relevant sections. "
            "If the information is incomplete, clearly state what is missing."
        )
    }
    user = {
        "role":"user",
        "content":(
            "Here are the relevant AAOIFI excerpts:\n\n"
            + "\n---\n".join(contexts)
            + f"\n\nQuestion: {eng_question}\nAnswer:"
        )
    }
    chat = openai.chat.completions.create(
        model=CHAT_MODEL,
        messages=[system, user],
        temperature=0.3,
        max_tokens=512
    )
    eng_answer = chat.choices[0].message.content.strip()

    # â”€â”€ 4) Ğ•ÑĞ»Ğ¸ Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ±Ñ‹Ğ» Ğ½Ğ° ĞºĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ†Ğµ, Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ â”€
    if is_cyrillic:
        tran_back = openai.chat.completions.create(
            model=CHAT_MODEL,
            messages=[
                {"role":"system","content":"Translate the following into Russian, preserving meaning and style:"},
                {"role":"user",  "content": eng_answer}
            ]
        )
        return tran_back.choices[0].message.content.strip()

    # â”€â”€ 5) Ğ˜Ğ½Ğ°Ñ‡Ğµ â€” Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ½Ğ° Ğ°Ğ½Ğ³Ğ»Ğ¸Ğ¹ÑĞºĞ¾Ğ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    return eng_answer

# â”€â”€â”€ 5. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ polling-Ñ†Ğ¸ĞºĞ» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    offset = None
    while True:
        for u in get_updates(offset):
            offset = u["update_id"] + 1
            msg    = u.get("message", {})
            text   = msg.get("text")
            chat_id= msg.get("chat", {}).get("id")
            if not text or not chat_id:
                continue

            if text.startswith("/start"):
                send_message(chat_id, "ğŸ‘‹ Salam! Ask me anything about AAOIFI standards.")
            else:
                send_message(chat_id, "âŒ› Thinkingâ€¦")
                try:
                    ans = answer_question(text)
                except Exception as e:
                    ans = "âŒ Error:\n" + str(e)
                send_message(chat_id, ans)

        time.sleep(1)

if __name__ == "__main__":
    main()
